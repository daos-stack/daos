# Introduction
Arguably, one of the worst things a data storage system can do is to return incorrect data without the requester knowing. While each component in the system (network layer, storage devices) may offer protection against silent data corruption, DAOS will provide end-to-end data integrity using checksums to better ensure that user data is not corrupted silently.

For DAOS, end-to-end means that the client will calculate and verify checksums, providing protection for data through the entire I/O stack. During a write or update, the DAOS Client library (libdaos.so) calculates a checksum and appends it to the RPC message before transferred over the network.
Depending on the situation, the DAOS Server may or may not calculate checksums to verify the data on receipt. On a fetch, the DAOS Server will send a known good checksum with the requested data to the DAOS Client, which will calculate checksums on the data received and verify.

# Configuration
Checksum configuration is done per container and is disabled by default. To enable and configure checksums, the following container properties are used during container create. Note that currently, once a container is created, its checksum configuration cannot be changed.

## Checksum Container Setup

- `DAOS_PROP_CO_CSUM`: Type of checksum algorithm to use. Supported values are

```c
  DAOS_PROP_CO_CSUM_OFF, // default
  DAOS_PROP_CO_CSUM_CRC16,
  DAOS_PROP_CO_CSUM_CRC32,
  DAOS_PROP_CO_CSUM_CRC64,
```

- `DAOS_PROP_CO_CSUM_CHUNK_SIZE`: Discussed in the Array Values section below, checksums will be calculated for a subset of the data. The number of bytes of this subset will be configured as the "Chunk size". The default is 32K
- `DAOS_PROP_CO_CSUM_SERVER_VERIFY`: Because of the probable decrease to
  IOPS, in most cases, it is not desired to verify checksums on an object
  update on the server side. It is sufficient for the client to verify on
  a fetch because any data corruption, whether on the object update,
  storage, or fetch, will be caught. However, there is an advantage to
  knowing if corruption happens on an update. The update would fail
  right away, indicating to the client to retry the RPC or report an
  error to upper levels.

# Keys and Value Objects
Because DAOS is a key/value store, the data for both keys and values will be protected, however, the approach for both is slightly different. For the two different value types, single and array, the approach is also slightly different.

## Keys
On an update and fetch, the client will calculate a checksum for the data used as the distribution and attribute keys and will send it to the server within the RPC. The server verifies the keys with the checksum.
While enumerating keys, the server will calculate checksums for the keys and pack within the RPC message to the client. The client will verify the keys received.

Note that Checksums for keys are not stored on the server. A hash of the key is calculated and used to index the key in the server tree of the keys (see [VOS Key Array Stores](../../src/vos/README.md#key-array-stores)). It is also expected that keys are stored only in Storage Class Memory which has reliable data integrity protection.

## Values
On an update, the client will calculate a checksum for the data of the value and will send it to the server within the RPC. If "server verify" is enabled, the server will calculate a new checksum for the value and compare with the checksum received from the client to verify the integrity of the value. If the checksums don't match, then data corruption has occurred and an error is returned to the client indicating that the client should try the update again. Whether "server verify" is enabled or not, the server will store the checksum. See [VOS](../../src/vos/README.md) for more info about checksum management and storage in VOS.

On a fetch, the server will return the stored checksum to the client with the values fetched so the client can verify the values received. If the checksums don't match, then the client will fetch from another replica if available in an attempt to get uncorrupted data.

There are some slight variations to this approach for the two different types of values. (See [Storage Model](storage.md) for more details about the single value and array value types)

### Single Value
A Single Value is an atomic value, meaning that writes to a single value will update the entire value and reads retrieve the entire value. Other DAOS features such as Erasure Codes might split a Single Value into multiple shards to be distributed among multiple storage nodes. Either the whole Single Value (if going to a single node) or each shard (if distributed) will have a checksum calculated, sent to the server, and stored on the server.

Note that it is possible for a single value, or shard of a single value, to be smaller than the checksum derived from it. It is advised that if an application needs many small single values to use an Array Type instead.

### Array Values
Unlike Single Values, Array Values can be updated and fetched at any part of an array. In addition, updates to an array are versioned, so a fetch can include parts from multiple versions of the array. Each of these versioned parts of an array are called extents. The following diagrams illustrate a couple examples (also see [VOS Key Array Stores](../../src/vos/README.md#key-array-stores) for more information):

<div>
A single extent update (blue line) from index 2-13. A fetched extent (orange line) from index 2-6. The fetch is only part of the original extent written.

![](../graph/data_integrity/array_example_1.png)
</div>

<div>
Many extent updates and different epochs. A fetch from index 2-13 requires parts from each extent.

![Array Example 2](../graph/data_integrity/array_example_2.png)

</div>

The nature of the array type requires that a more sophisticated approach to creating checksums is used. DAOS uses a "chunking" approach where each extent will be broken up into "chunks" with a predetermined "chunk size." Checksums will be derived from these chunks. Chunks are aligned with an absolute offset (starting at 0), not an I/O offset. The following diagram illustrates a chunk size configured to be 4 (units is arbitrary in this example). Though not all chunks have a full size of 4, an  absolute offset alignment is maintained. The gray boxes around the extents represent the chunks.

<img src="../graph/data_integrity/array_with_chunks.png" width="700" />

(See [Object Layer](../../src/object/README.md) for more details about the checksum process on object update and fetch)

# Checksum calculations
The actual checksum calculations are done by the [isa-l](https://github.com/intel/isa-l) and [isa-l_crypto](https://github.com/intel/isa-l_crypto) libraries. However, these libraries are abstracted away from much of DAOS and a common checksum library is used with appropriate adapters to the actual isa-l implementations. [common checksum library](../../src/common/README.md#checksum)
