hosts:
  test_servers:
    - server-A
    - server-B
  test_clients:
    - client-A

timeout: 10M

# If there are more than around 5 NVMe disks, it takes longer than the default timeout for
# the engine to start, so increase it to 60 sec.
daos_server:
  pattern_timeout: 60
server_config:
  name: daos_server
  servers:
    log_mask: INFO
    bdev_class: nvme
    bdev_list: ["0000:00:00.0","0000:00:00.1","0000:00:00.2","0000:00:00.3",
                "0000:00:00.4","0000:00:00.5","0000:00:00.6","0000:00:00.7",
                "0000:00:00.8","0000:00:00.9"]
    scm_class: dcpm
    scm_list: ["/dev/pmem0"]

pool_size_ratio:
  size: 50%
  control_method: dmg
pool_size_value:
  scm_size: 100G
  nvme_size: 500G
  control_method: dmg

container_wo_rf:
  type: POSIX
  control_method: daos
container_with_rf:
  type: POSIX
  control_method: daos
  properties: rf:1

ior:
  client_processes:
    np: 1
  iorflags:
    flags: "-k -D 10 -v -w -W"
    api: DFS
    # We wait for a few seconds before excluding a target. If the IOR finishes too
    # quickly, the test will not work. We use -D (deadlineForStonewalling) 10, so the
    # process ends in about 10 sec. The following transfer_size - block_size combination
    # takes about 42 sec in the Shared Cluster. Adjust the value based on the system so
    # that it takes longer than the -D value.
    transfer_size: '512K'
    block_size: '30G'
    write_x: 4
    read_x: 2
object_class:
  wo_rf:
    oclass: "SX"
  with_rf:
    oclass: "RP_2G1"
