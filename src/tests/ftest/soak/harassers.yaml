hosts:
  # servers if no server partition is defined
  test_servers: 8
  # servers if a server partition is defined
  # server_partition: daos_server
  client_partition: daos_client
  # client_reservation: daos-test
orterun:
  allow_run_as_root: true
# This timeout must be longer than the test_timeout param (+15minutes)
timeout: 24H30M
setup:
  start_servers: true
  start_agents: true
server_config:
  name: daos_server
  control_log_mask: INFO
  control_log_file: daos_control0.log
  crt_timeout: 120
  engines_per_host: 2
  engines:
    0:
      pinned_numa_node: 0
      nr_xs_helpers: 2
      fabric_iface_port: 31317
      log_file: daos_server0.log
      log_mask: INFO
      env_vars:
        - FI_UNIVERSE_SIZE=16383
        - DD_MASK=rebuild
      storage: auto
    1:
      pinned_numa_node: 1
      nr_xs_helpers: 2
      fabric_iface_port: 31417
      log_file: daos_server1.log
      log_mask: INFO
      env_vars:
        - FI_UNIVERSE_SIZE=16383
        - DD_MASK=rebuild
      storage: auto
# pool_params - attributes of the pools to create; Currently only create one
pool_jobs:
  size: 75%
  rebuild_timeout: 600
  pool_query_timeout: 120
pool_reserved:
  size: 10%
  rebuild_timeout: 600
  pool_query_timeout: 120
container:
  type: POSIX
  properties: cksum:crc16,cksum_size:16384,srv_cksum:on
  control_method: daos
  daos_timeout: 30
container_reserved:
  type: POSIX
  properties: cksum:crc16,cksum_size:16384,srv_cksum:on,rd_fac:1
  file_oclass: SX
  dir_oclass: SX
  control_method: daos
  daos_timeout: 30
# test_params - Defines the type of test to run and how long it runs
#               It also defines how many pools and jobs to create
#               name:                The name of the Avocado testcase
#               test_timeout:        The overall timeout in hours
#               test_iteration:      values 1 or -1; -1 is used to cause the
#                                    IOR -T x to end cmd.  i = 100000000
#                                    (does not seem to work)
#               nodesperjob:         slurm -N param; -1 indicates all nodes
#                                    in -partition
#               poollist:            defines pools to create for jobs
#               joblist:             defines workload per slurm scripts
#               harasserlist:        defines the harassers to run in test
soak_harassers:
  name: soak_harassers
  # harasser test timeout in hours
  single_test_pool: false
  test_timeout:
    test_soak_online_harassers: 24
    test_soak_offline_harassers: 24
  # maximum timeout for a single job in test in minutes
  joblist:
    - ior_harasser
    - fio_harasser
    - mdtest_harasser
  # one harrasser is run during each pass of soak jobs
  harasserlist:
    test_soak_offline_harassers:
      - exclude_reintegrate-offline
      - server-stop_server-start-offline
      - server-stop_server-reintegrate-offline
      - extend-pool-offline
      # - vmd-identify-check-offline
      - reboot_reboot-reintegrate-offline
    test_soak_online_harassers:
      - exclude_reintegrate
      - server-stop_server-start
      - server-stop_server-reintegrate
      - extend-pool
      # - vmd-identify-check
      - reboot_reboot-reintegrate
  harasser_to: 1200
  # drain rank from all pools before stopping server
  enable_drain: true
  # continue test if container destroy fails
  ignore_soak_errors: true
  enable_intercept_lib: false
  enable_remote_logging: false
  enable_scrubber: false
# Commandline parameters
# Benchmark and application params
# IOR params -a DFS and -a MPIIO
# sequential
ior_harasser:
  job_timeout: 30
  nodesperjob:
    - 2
    - 4
    - 8
  taskspernode:
    - 2
    - 4
    - 8
    - 16
  api:
    - DFS
    - MPIIO
    - POSIX
    - HDF5
  test_file: daos:/testFile
  flags: -v -w -W -r -R -F -k
  block_size:
    - '64M'
  repetitions: 1
  transfer_size:
    - '32k'
    - '1m'
  segment_count: 1
  dfs_oclass:
    - ["EC_2P1GX", "RP_2GX"]
    - ["EC_4P2GX", "RP_3GX"]
  dfuse:
    mount_dir: "/tmp/daos_dfuse/ior"
    disable_caching: true
fio_harasser:
  api:
    - POSIX
  job_timeout: 30
  names:
    - global
    - test
  global:
    directory: "/tmp/daos_dfuse/fio/"
    ioengine: 'libaio'
    thread: 1
    group_reporting: 1
    direct: 1
    verify: 'crc64'
    iodepth: 16
  test:
    numjobs: 1
  soak:
    blocksize:
      - '4K'
      - '1M'
    size:
      - '1G'
    rw:
      - 'rw'
      - 'randrw'
    oclass:
      - ["EC_2P1GX", "RP_2GX"]
      - ["EC_4P2GX", "RP_3GX"]
  dfuse:
    mount_dir: "/tmp/daos_dfuse/fio/"
    disable_caching: true
mdtest_harasser:
  # maximum timeout for a single job in test in minutes
  job_timeout: 30
  nodesperjob:
    - 1
    - 4
    - 8
  taskspernode:
    - 4
    - 16
  test_dir: "/"
  api:
    - DFS
    - POSIX
  iteration: 1
  num_of_files_dirs: 3000
  pre_iter: 10
  flags: '-v'
  write_bytes:
    - 3901
  read_bytes:
    - 3901
  depth:
    - 10
    - 0
  dfs_oclass:
    - ["EC_2P1G1", "RP_2G1"]
    - ["EC_4P2G1", "RP_3G1"]
  dfs_destroy: false
  dfuse:
    mount_dir: "/tmp/daos_dfuse/mdtest/"
    disable_caching: true
hdf5_vol:
  plugin_path: "/usr/lib64/mpich/lib"
events:
  - "mce: [Hardware Error]: Machine check events logged"
  - "Package temperature above threshold"
monitor:
  - "/usr/bin/free -h"
  - "/usr/bin/vmstat -w"
  - "ps -C daos_engine -o %mem,%cpu,cmd"
enable_telemetry: true
