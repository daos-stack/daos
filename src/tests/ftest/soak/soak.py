#!/usr/bin/python
'''
(C) Copyright 2019 Intel Corporation.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

GOVERNMENT LICENSE RIGHTS-OPEN SOURCE SOFTWARE
The Government's rights to use, modify, reproduce, release, perform, display,
or disclose this software are subject to the terms of the Apache License as
provided in Contract No. B609815.
Any reproduction of computer software, computer software documentation, or
portions thereof marked with this legend must also reproduce the markings.
'''

import os
import sys
import json
import time
from avocado import Test

sys.path.append('./util')
sys.path.append('../util')
sys.path.append('../../../utils/py')
sys.path.append('./../../utils/py')
import ServerUtils
import WriteHostFile
import IorUtils
import slurm_utils
import dmg_utils
from daos_api import DaosContext, DaosPool, DaosApiError

# global stores intermediate test results
_soak_results = {}

def job_done(args):
    """
    This is a callback function called when a job is done

    handle --which job, i.e. the job ID
    state  --string indicating job completion status
    """
    global _soak_results
    _soak_results[args["handle"]] = args["state"]

class Soak(Test):
    """
    Test class Description: DAOS Soak test cases
    """
    def create_pool(self):
        """
        Creates a pool that the various tests use for storage.
        """

        createmode = self.params.get("mode", '/run/pool1/createmode/*/')
        createuid = os.geteuid()
        creategid = os.getegid()
        createsetid = self.params.get("setname", '/run/pool1/createset/')
        createsize = self.params.get("size", '/run/pool1/createsize/')
        self.createsvc = self.params.get("svcn", '/run/pool1/createsvc/')

        self.pool = DaosPool(self.context)
        self.pool.create(createmode, createuid, creategid,
                         createsize, createsetid, None, None,
                         self.createsvc)

    def get_ior_job(self, spec, processes, name):
        """
        Builds an IOR command string based on input parameters

        spec --which set of IOR params to read in the test yaml

        """

        # for the moment build IOR
        #IorUtils.build_ior(self.basepath)

        # which job spec to read
        spec = "/run/" + spec + "/"

        iteration = self.params.get("iter", spec + 'iteration/')
        ior_flags = self.params.get("F", spec + 'iorflags/')
        transfer_size = self.params.get("t", spec + 'transfersize/')
        record_size = self.params.get("r", spec + 'recordsize/*')
        stripe_size = self.params.get("s", spec + 'stripesize/*')
        stripe_count = self.params.get("c", spec + 'stripecount/')
        async_io = self.params.get("a", spec + 'asyncio/')
        object_class = self.params.get("o", spec + 'objectclass/')

        self.partition = self.params.get("partition",
                                         '/run/hosts/test_machines/')

        pool_uuid = self.pool.get_uuid_str()
        tmplist = []
        svc_list = ""
        for i in range(self.createsvc):
            tmplist.append(int(self.pool.svc.rl_ranks[i]))
            svc_list += str(tmplist[i]) + ":"
        svc_list = svc_list[:-1]

        block_size = '1536m'

        if stripe_size == '8m':
            transfer_size = stripe_size

        hostfile = os.path.join(self.tmpdir, "ior_hosts_" + name)

        cmd = IorUtils.get_ior_cmd(ior_flags, iteration, block_size,
                                   transfer_size, pool_uuid, svc_list,
                                   record_size, stripe_size, stripe_count,
                                   async_io, object_class, self.basepath,
                                   hostfile, processes)
        return cmd

    def setUp(self):

        # intermediate results are stored in this global
        # start off with it empty
        _soak_results.clear()

        self.partition = None

        # initialize anything we rely on existing
        self.pool = None
        self.hostlist_servers = None

        # get paths from the build_vars generated by build
        with open('../../../.build_vars.json') as thefile:
            build_paths = json.load(thefile)
        self.basepath = os.path.normpath(build_paths['PREFIX']  + "/../")

        # workdir was not successful, not sure why right now
        self.tmpdir = self.basepath + "/install/tmp"
        try:
            os.makedirs(self.tmpdir)
        except:
            pass

        # setup the DAOS python API
        self.context = DaosContext(build_paths['PREFIX'] + '/lib/')

        # start the servers
        self.hostlist_servers = self.params.get("daos_servers",
                                                '/run/hosts/test_machines/*')
        filename = WriteHostFile.WriteHostFile(self.hostlist_servers,
                                               self.workdir)
        self.server_group = self.params.get("server_group", '/server/',
                                            'daos_server')
        print("Servers {} group {} basepath {}".format(self.hostlist_servers,
                                                       self.server_group,
                                                       self.basepath))
        ServerUtils.runServer(filename, self.server_group, self.basepath)

        # setup the storage
        self.create_pool()

    def tearDown(self):
        ServerUtils.stopServer(hosts=self.hostlist_servers)

    def test_soak_1(self):
        """
        Test ID: DAOS-2192
        Test Description: This test runs 2 DAOS API IOR jobs.
        :avocado: tags=soak1
        """

        try:
            # retrieve job parameters
            s1_job1_name = self.params.get("name", '/run/job1/')
            s1_job1_nodes = self.params.get("nodes", '/run/job1/')
            s1_job1_processes = self.params.get("process_per_node",
                                                '/run/job1/')
            s1_job1_spec = self.params.get("jobspec", '/run/job1/')
            cmd = [self.get_ior_job(s1_job1_spec, s1_job1_processes,
                                    s1_job1_name)]

            # write out a slurm job script
            output = os.path.join(self.tmpdir, s1_job1_name + "_results.out")
            script1 = slurm_utils.write_slurm_script(self.tmpdir, s1_job1_name,
                                                    output,
                                                    int(s1_job1_nodes), cmd)
            # queue it up to run and register a callback to retrieve results
            job_id = slurm_utils.run_slurm_script(script1)
            slurm_utils.register_for_job_results(job_id, job_done, maxwait=3600)

            # queue up a second job
            s1_job2_name = self.params.get("name", '/run/job2/')
            s1_job2_nodes = self.params.get("nodes", '/run/job2/')
            s1_job2_processes = self.params.get("process_per_node",
                                                '/run/job2/')
            s1_job2_spec = self.params.get("jobspec", '/run/job2/')
            cmd = [self.get_ior_job(s1_job2_spec, s1_job2_processes,
                                    s1_job2_name)]

            output = os.path.join(self.tmpdir, s1_job2_name + "_results.out")
            script2 = slurm_utils.write_slurm_script(self.tmpdir, s1_job2_name,
                                                    output,
                                                    int(s1_job2_nodes), cmd)
            id2 = slurm_utils.run_slurm_script(script2)
            slurm_utils.register_for_job_results(id2, job_done, maxwait=3600)

            # wait for all the jobs to finish
            global _soak_results
            while len(_soak_results) < 2:
                time.sleep(10)

            for job, result in _soak_results.iteritems():
                if result != "COMPLETED":
                    self.fail("Soak job: {} didn't complete as expected: {}".
                              format(job, result))

        except (DaosApiError, IorUtils.IorFailed) as error:
            self.fail("<Soak Test 1 Failed>\n {}".format(error))
        finally:
            try:
                os.remove(script1)
            except:
                pass
            try:
                os.remove(script2)
            except:
                pass

    def test_soak_2(self):
        """
        Test ID: DAOS-2192
        Test Description: This test verifies that a dmg script can be submitted.
        :avocado: tags=soak2
        """

        script = None
        try:
            dmgcmds = DmgUtils.get_dmg_script("dmg1", self.params,
                                              self.basepath,
                                              self.workdir)

            s2_job1_name = self.params.get("name", '/run/job3/')
            s2_job1_nodes = self.params.get("nodes", '/run/job3/')

            output = os.path.join(self.tmpdir, s2_job1_name + "_results.out")

            script = slurm_utils.write_slurm_script(self.tmpdir, s2_job1_name,
                                                   output,
                                                   s2_job1_nodes, dmgcmds)
            job_id = slurm_utils.run_slurm_script(script)
            slurm_utils.register_for_job_results(job_id, job_done, maxwait=3600)

            # wait for all the jobs to finish
            global _soak_results
            while len(_soak_results) < 1:
                time.sleep(10)

            for job, result in _soak_results.iteritems():
                if result != "COMPLETED":
                    self.fail("Soak job: {} didn't complete as expected: {}".
                              format(job, result))

        except (DaosApiError, IorUtils.IorFailed) as error:
            self.fail("Soak Test 2 Failed/n {}".format(error))
        finally:
            try:
                os.remove(script)
            finally:
                pass

    def test_soak_3(self):
        """
        Test ID: DAOS-2192
        Test Description: this time try a dmg command combined with IOR run
        Use Cases:
        :avocado: tags=soak3
        """

        script1 = None
        script2 = None
        try:
            # retrieve IOR job parameters
            s3_job1_name = self.params.get("name", '/run/job1/')
            s3_job1_nodes = self.params.get("nodes", '/run/job1/')
            s3_job1_processes = self.params.get("process_per_node",
                                                '/run/job1/')
            s3_job1_spec = self.params.get("jobspec", '/run/job1/')
            cmd = self.get_ior_job(s3_job1_spec, s3_job1_processes,
                                   s3_job1_name)

            # write out a slurm job script
            output = os.path.join(self.tmpdir, s3_job1_name + "_results.out")
            script1 = slurm_utils.write_slurm_script(self.tmpdir, s3_job1_name,
                                                    output,
                                                    int(s3_job1_nodes), [cmd])
            # queue it up to run and register a callback to retrieve results
            job_id = slurm_utils.run_slurm_script(script1)
            slurm_utils.register_for_job_results(job_id, job_done, maxwait=3600)

            # now do the dmg job
            dmgcmds = DmgUtils.get_dmg_script("dmg1", self.params,
                                              self.basepath,
                                              self.workdir)

            s3_job2_name = self.params.get("name", '/run/job3/')
            s3_job2_nodes = self.params.get("nodes", '/run/job3/')
            output = os.path.join(self.tmpdir, s3_job2_name + "_results.out")
            script2 = slurm_utils.write_slurm_script(self.tmpdir, s3_job2_name,
                                                    output, s3_job2_nodes,
                                                    dmgcmds)
            job_id = slurm_utils.run_slurm_script(script2)
            slurm_utils.register_for_job_results(job_id, job_done, maxwait=3600)

            # wait for all the jobs to finish
            global _soak_results
            while len(_soak_results) < 2:
                time.sleep(10)

            for job, result in _soak_results.iteritems():
                if result != "COMPLETED":
                    self.fail("Soak job: {} didn't complete as expected: {}".
                              format(job, result))

        except (DaosApiError, IorUtils.IorFailed) as error:
            self.fail("Soak Test 3 Failed\n {}".format(error))
        finally:
            try:
                os.remove(script1)
            except:
                pass
            try:
                os.remove(script2)
            except:
                pass
