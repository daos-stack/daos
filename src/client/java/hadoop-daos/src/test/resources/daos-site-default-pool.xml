<configuration>
  <property>
    <name>fs.defaultFS</name>
    <value>daos:///</value>
  </property>
  <property>
    <name>fs.daos.pool.uuid</name>
    <value>uuid of pool</value>
    <description>UUID of DAOS pool</description>
  </property>
  <property>
    <name>fs.daos.container.uuid</name>
    <value>uuid of container</value>
    <description>UUID of DAOS container which created with "--type posix"</description>
  </property>
  <property>
    <name>c2.fs.daos.pool.uuid</name>
    <value>uuid of pool</value>
    <description>UUID of DAOS pool</description>
  </property>
  <property>
    <name>c2.fs.daos.container.uuid</name>
    <value>c1 uuid</value>
    <description>UUID of DAOS container which created with "--type posix"</description>
  </property>
  <property>
    <name>fs.daos.read.buffer.size</name>
    <value>8388608</value>
    <description>size of direct buffer for reading data from DAOS. Default is 8m.
      Value range is 1m - 2g.
    </description>
  </property>
  <property>
    <name>c2.fs.daos.read.buffer.size</name>
    <value>234567</value>
    <description>size of direct buffer for reading data from DAOS. Default is 8m.
      Value range is 1m - 2g.
    </description>
  </property>
  <property>
    <name>fs.daos.write.buffer.size</name>
    <value>8388608</value>
    <description>size of direct buffer for writing data to DAOS. Default is 8m.
      Value range is 1m - 2g.
    </description>
  </property>
  <property>
    <name>c2.fs.daos.write.buffer.size</name>
    <value>234567</value>
    <description>size of direct buffer for writing data to DAOS. Default is 8m.
      Value range is 1m - 2g.
    </description>
  </property>
  <property>
    <name>fs.daos.block.size</name>
    <value>134217728</value>
    <description>
      size for splitting large file into blocks when read by Hadoop. Default is 128m.
      Value range is 16m - 2m.
    </description>
  </property>
  <property>
    <name>c2.fs.daos.block.size</name>
    <value>1234567</value>
    <description>
      size for splitting large file into blocks when read by Hadoop. Default is 128m.
      Value range is 16m - 2m.
    </description>
  </property>
  <property>
    <name>fs.daos.chunk.size</name>
    <value>1048576</value>
    <description>
      size of DAOS file chunk. Default is 1m.
      Value range is 4k - 2g.
    </description>
  </property>
  <property>
    <name>c2.fs.daos.chunk.size</name>
    <value>1048</value>
    <description>
      size of DAOS file chunk. Default is 1m.
      Value range is 4k - 2g.
    </description>
  </property>
  <property>
    <name>fs.daos.preload.size</name>
    <value>4194304</value>
    <description>
      size for pre-loading more than requested data from DAOS into internal buffer when read.
      Value range is 1m - 2g.
    </description>
  </property>
  <property>
    <name>c2.fs.daos.preload.size</name>
    <value>-1</value>
    <description>
      size for pre-loading more than requested data from DAOS into internal buffer when read.
      Value range is 1m - 2g.
    </description>
  </property>
</configuration>